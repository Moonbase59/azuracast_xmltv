#!/usr/bin/env python3
# encoding: utf-8

"""azuracast_xmltv

Fetches EPG info from an AzuraCast (web radio) instance
and provides XMLTV Tuner M3U, EPG XML, and RSS feed listings.
"""

# Note: Requires Python 3.7 or newer (for correct strftime/strptime handling).
#
# One AzuraCast instance can have multiple stations (= "channels").
# Each station can have multiple mounts, which we ignore for EPG purposes,
# since they are supposed to play the same content.
# The XMLTV EPG will contain schedule items for ALL stations,
# since some programs can't handle too many separate EPG files.
#
# Mounts are important for the M3U playlist files, though.
# We will create one M3U playlist file per station (good for resellers,
# or if you want to publicize only certain stations), plus an overall one.

# 2023-10-15 - Moonbase59 - initial public version
# 2023-10-16 - Moonbase59 - v0.3.1
#   - rework API access, use a class
# 2023-10-17 - Moonbase59 - v0.4.0
#   - PEP8 formatting
#   - EPG for more than 2 days by repeating the API call
# 2023-10-18 - Moonbase59 - v0.4.1
#   - better HTTP request error handling
# 2023-10-18 - Moonbase59 - v0.5.0
#   - lots of real-life tests, better error handling
#   - tests using the "xmltv-util" package: tv_validate_file, tv_to_text, etc.
#   - work around AzuraCast API quirks (multi-day schedule, duplicates removal)
#   - provide much nicer EPG programme entries if using an API key (=you own station)
#       - customizable Live Show title/sub-title/description (streamer/DJ info)
#       - customizable Live Show DJ info (mis-using Streamer Comment field)
#       - Live Show DJ image (if provided in AzuraCast); this is added as an
#         image of type "person" in the programme's <presenter> info.
#         Not all clients may support this (they'll just ignore it).
#       - customizable listener requests info (for playlists that have requests enabled)
#       - customizable syndication info (for playlists that are remote streams)
# 2023-10-19 - Moonbase59 - v0.5.1
#   - Add 'User-Agent' header for API request, so azuracast_xmltv can be better identified
# 2023-10-19 - Moonbase59 - v0.5.2
#   - Sanitize station name to get RFC2383-compliant (it's user input, after all).
#   - Use 'hostname' instead of 'netloc' to create channel ID; fixes #1.
#     We still leave 'netloc' in the EPG as 'source-info-name' so we know where it
#     really came from.
#   - PEP8 formatting.
# 2023-10-19 - Moonbase - v0.6.0
#   - add option -f/--fillgaps and logic to find gaps between programmes and fill them
#     with dummy entries. This can be used for stations that have a 24/7
#     general rotation and wish to advertise playout in between show blocks.
#     If an API key is used, this can also include the playlist names involved
#     to build the general rotation. Name your playlists appropriately.
#     If ANY of the involved playlists has listener requests enabled,
#     this will be shown (using the requests_enabled parsing).
#   - removed superfluous whitespace in programme description, also eliminating
#     extra spaces/newlines left over from using empty variables.
#   - MUCH improved "{variable}" parsing, and many more that can be used
#   - added append_to_description text that can be added to EVERY programme,
#     can be used for legalese, or website hints.
# 2023-10-21 - Moonbase - v0.7.0
#   - In the M3Us, the mounts are now sorted by their display names,
#     and the default mount put at the beginning.
#     This is intended for players that immediately start playout (they should
#     play the default mount). Human readability also improved by sorting.
#   - -t/--tvurl option: generates 'url-tvg' and 'x-tvg-url' tags on #EXTM3U line,
#     for players like KODI that can thus automatically find the corresponding EPG.
#     Note: ONLY works when the generated M3U and XML files can be found under
#     the '/xmltv/' path on your AzuraCast server, for example at
#     https://example.com/xmltv/example.com.xml.
# 2023-10-22 - Moonbase - v0.8.0
#   - fix {remote_url} showing public player URL
#   - add option -c/--customplayer URL to point to a customized player
#     on a station's website instead of the AzuraCast web player
#     when using the {player_url} or {request_url} variables.
# 2023-10-22 - Moonbase - v0.8.1
#   - minor code refactoring
#   - fix #2 "TypeError: replace() argument 2 must be str, not None"
#     (JSON null strings from API weren’t replaced by an empty string)
# 2023-10-22 - Moonbase - v0.9.0
#   - reinstate the defaults being shown in help
#   - write formatter class for argparse, to wrap help text nicely
#   - add limits (and check) for EPG days (1-30 days in the future)
#   - change API schedule getter to use (undocumented) 'start' and 'end' parameters
#   - changed unused strings default to None instead of ''. Both are Falsy.
#   - use os.path.join() to create M3U and XML file names
# 2023-10-23 - Moonbase - v0.10.0
#   - add option -g/--gzip to create a '.gz' gzip-compressed version of the EPG
#     in addition to the .xml file. This can drastically reduce transmission time
#     if the client supports it (many do).
#   - move all imports to top (no late imports anymore) so we get errors
#     for ALL missing modules on first install.
# 2023-10-24 - Moonbase - v0.11.0
#   - add option -r/--radio to add a 'radio="true"' tag in M3U #EXTINF
#     for streams whose display name DOESN’T contain certain "video" keywords
#     This is for media centers like KODI that can separate Radio & TV streams
#     (if 'radio' is true, the stream will appear in  the "Radio" menu, not "TV")
# 2023-10-29 - Moonbase - v0.12.0
#   - add option --rss, a RSS 2.0 Feed generator (experimental for now)
#     (creates one file per station, well cacheable, "station_shortcode.rss")
#     Makes sense only when also served from the "/xmltv" server path.
#   - use correct (global) language attribute in XMLTV XML files and RSS
# 2023-10-30 - Moonbase - v0.12.2
#   - an approach to make URLs in the RSS description clickable by turning them
#     into HTML anchors. Based on John Gruber’s "Liberal Regex Pattern for Any URLs"
#   - Some wording changes in the sample texts.
# 2023-10-30 - Moonbase - v0.12.3
#   - Fix #10: occasionally finds the wrong playlist in a schedule if multiple
#     playlists have the same name (which IS allowed), AND you were using an API key.
#   - Fix #9: display problem in Liferea 1.13.7: It messes up the following text
#     if a tag was empty, like <h3>{subtitle}</h3>. Simply adding a blank helps
#     and doesn’t conflict with other readers.
#   - Added "No worries..." to "Edit this file..." help text.
# 2023-10-30 - Moonbase - v0.13.0
#   - Fix crash for streamer schedule (presenter credits lookup problem in RSS)
#   - rework credits lookup & generation code for RSS and EPG
# 2023-10-30 - Moonbase - v0.13.1
#   - add <fh:complete/> and per-item validity <dcterms:valid> to RSS feed
#     This will enhance UX since the reader should remove historic items.
#     Validity indicates at what date & time the stream links actually play
#     what is described in the item (programme).
# 2023-10-31 - Moonbase - v0.13.2
#   - refactor "isodate()" into "rfc3339_date()" -- more reliable datetime strings
# 2023-11-01 - Moonbase - v0.14.0
#   - add aggregate M3U per server "<domain>.m3u", allows easier integration
#     of ALL stations in programs like Jellyfin, KODI, Hypnotix, etc.
#   - add --group option; overrides M3U "group-title" from station name
#     to something like "Radio-DE", for easier integration into other lists,
#     or just keeping your stations together.
#   - some code cleanup, mainly urljoin(), and more PEP8
#   - '/xmltv' server path now configurable. For interoperability, YOU SHOULDN'T.
# 2023-11-06 - Moonbase - v0.15.0
#   - tested & fixed some edge cases like stations w/o mounts (HLS-only),
#     stations w/ broadcasting or public pages disabled,
#     stations w/ no streams at all (no mounts, no HLS),
#     stations w/ nothing on schedule.
#   - fix unneeded abort on API errors (api.get returns empty list now)
#   - add api.verify() to check we’re actually accessing an AzuraCast server,
#     avoids producing useless files
#   - other minor code cleanup, unified error messages
#   - re-arrange #EXTINF for better human readability (Name Group Radio? ID Logo)
# 2023-11-06 - Moonbase - v0.16.0
#   - fix KeyError: 'image' when writing XML live programme and presenter has no image
#   - also check response Content-Type on API calls, so JSON decoder doesn’t error
#     AzuraCast always sets Content-Type=application/json
#   - switch from AutoPEP8 to black+isort codestyle; much better readable
#     Makefile included, use 'make format' to re-format code
# 2023-11-07 - Moonbase - v0.16.1
#   - harden initial AzuraCast server check.
# 2023-11-08 - Moonbase - v0.16.2
#   - minor cleanup
# 2023-11-08 - Moonbase - v0.17.0
#   - convert to Python module
#   - API access errors now shown, even if we continue (mostly no/wrong API key)
#   - some code cleanup

# version info
__version_info__ = ("0", "17", "0")
__version__ = ".".join(__version_info__)

APPNAME = "azuracast_xmltv"
VERSION = __version__
LICENSE = "MIT"
APPURL = "https://github.com/Moonbase59/azuracast_xmltv"


# *** USER CONFIGURABLE DEFAULTS START HERE ***

# Use the base URL here, NOT the public player URL!
# Note: The AzuraCast demo server is reset on the top of every hour,
# so you might get a CloudFlare Error 521. Just try again a few minutes later.
instance_url = "https://demo.azuracast.com"

# language used for content description in EPG & RSS
# us a language code permitted by the W3C for use in HTML
language = "en"

# EPG/RSS programme category to list (i.e. "Music", "Talk", ...)
category = "Music"

# "Moustache-type" variables that can be used when generating programmes:
# Those marked with a * are only available when using an API key,
# i.e. on your own station. They will be empty otherwise.
#
# ALWAYS AVAILABLE:
# - {station_name}
# - {station_description}
# - {station_website} -- the station website URL (not the AzuraCast URL)
# - {player_url}** -- station's web player URL
# - {year} -- start year of the programme
# - {category} -- (global) category ("Music")
#
# In "requests_enabled"*:
# - {playlist} -- playlist name
# - {request_url}** -- station's public player URL
#
# In "remote"*:
# - {playlist} -- playlist name
# - {remote_url} -- remote URL used in the playlist
#
# In "live":
# - {presenter} -- streamer/DJ name
# - {image_url}* -- streamer's image URL
# - {comments}* -- AzuraCast's Streamer Comments field content.
#   Comments should be used with care:
#   This field was originally meant for internal remarks only, you could leak data!
#
# In "gap_filler":
# - {playlists}* -- comma-separated list of playlist names that make up the general rotation
#   (enabled, type default, not on schedule).
#   So if your general rotation was made up of the playlists
#   'Classic Rock', 'Folk Rock' and 'Hard Rock', it would show
#   "Classic Rock, Folk Rock & Hard Rock".
#
# In "rss_feed_description":
# - {title} -- programme title
# - {subtitle} -- programme sub-title
# - {airdate} -- date of programme start "YYYY-MM-DD"
# - {airtime} -- programme start & end time "HH:MM–HH:MM"
# - {airtime_length} -- programme length "HH:MM"
# - {category} -- global category ("Music")
# - {desc} -- original programme description, generated from above elements
#   newlines in {desc} will automatically be converted to <br/>
#
#  * = This can only be used with an API key, i.e., on your own station.
# ** = Will point to AzuraCast's default web player, or a custom
#      web player URL on the station's website if -c/--customplayer is used.

# Text to add to a programme listing if listener requests are enabled
# for this playlist. Only works with API key.

# this will be used as a programme's title
requests_enabled_title = "{playlist} (requests enabled)"
# this will be used as a programme's subtitle
requests_enabled_subtitle = "Your favorite station. YOUR music."
# this will be appended to a programme's description, maybe use starting
# newline(s)
requests_enabled_description = """

Request lines open! Make this program YOURS by adding a request: Go to {request_url}, click on ›Request Song‹ and select your favorite."""

# Text to add to a programme listing if it is a syndicated playlist.
# (source: remote_url). Only works with API key.

# this will be used as a programme's title
remote_title = "{playlist}"
# this will be used as a programme's subtitle
remote_subtitle = ""
# this will be APPENDED to a programme's description
remote_description = """

(Syndicated content.)"""

# "Live" text to be shown when a streamer/DJ transmits a scheduled show

# this will be used as a programme's title
live_title = "Live: {presenter}"
# this will be used as a programme's subtitle
live_subtitle = ""
# this will be APPENDED to a programme's description
# REMOVE {comments} if you use that field for internal remarks, else you
# LEAK INTERNALS!
live_description = """

Live Show on {station_name}, hosted by {presenter}.
{comments}

Tune in at {station_website}!"""

# "Gap Filler" text to be shown when a programme is actually a gap filler.
# After parsing, the gap_filler_title will be used as playlist name and the result
# RE-PARSED by the requests_enabled parser, if ANY of the involved playlists has
# requests enabled. Descriptions from here and the requests enabled parsing will
# be APPENDED to each other (the request text coming beneath).

# this will be used as a programme's title
gap_filler_title = "24/7 Rock"
# this will be used as a programme's subtitle
gap_filler_subtitle = "{playlists}"
# this will be the programme's description
# Your text should make sense even if {playlists} is empty!
# Multiple successive blanks will be automatically replaced by a single blank.
gap_filler_description = """Your favorite songs, 24 hours a day, 7 days a week.
The best {playlists} in {year} — just here, on {station_name}."""

# Text to be appended to EVERY programme description (seldom needed)
append_to_description = """

Program Copyright © {year} {station_name} — {station_description}
Visit us on {station_website}."""

# RSS Feed description, HTML allowed here
# Note some feed readers strip many HTML elements, so TEST.
# Liferea 1.13.7 chokes on empty tags, and messes up the display,
# so add a blank to the <h3>{subtitle}</h3> in case the
# subtitle is empty.
rss_feed_description = """<h2>{title}</h2>
<h3>{subtitle} </h3>
<p><strong>{airdate}&emsp;{airtime}</strong> ({airtime_length})&emsp;{station_name} ({category})</p>
<p>{desc}</p>"""


# -a/--apikey option default:
# Add an AzuraCast API key here for extended functionality
# An API key is needed to include streams hidden from public pages,
# like an extra video stream.
api_key = None

# -p/--public option default:
# If 'public_only' is True, we will only list stations and mounts marked
# as public.
public_only = False

# -m/--m3u option default:
# No need to recreate the XMLTV M3U Tuner file if only updating the EPG.
# You WILL need to use the -u/--m3u option to initially create the tuner file,
# or when you have made changes to the streams in AzuraCast.
make_m3u = False

# --group option default:
# M3U "group-title" ('' = Use station name)
# For later integration into larger lists, use something like "Radio-DE".
# Some clients (KODI’s IPTV Simple Client) support multiple groups,
# separated by ";". Example: "My Group;Radio-DE"
# You CAN use an empty value in multiple groups, which will be filled
# with your Station Name, i.e.
#   ";Radio-DE" will expand to "My station;Radio-DE"
#   "Radio;;Radio-DE" will expand to "Radio;My station;Radio-DE"
m3u_group_title = ""

# -r/--radio option default
# Add a 'radio="true"' tag in the M3U’s #EXTINF line for streams
# whose display name doesn’t contain the word "video".
# This is for media centers like KODI that can separate Radio & TV streams
# (if 'radio' is true, the stream will appear in  the "Radio" menu, not "TV")
add_radio_tag = True
# list of words in stream display name
# that will EXCLUDE a stream from getting the 'radio="true"' #EXTINF tag.
# Comparison is done in "casefold" mode, i.e. case-insensitively,
# with characters like the German "ß" expanded to "ss".
# Example:
#   "Nite Radio (128kbps MP3)" will be listed as "Radio" in KODI
#   "Nite Radio Video Stream" will be listed as "TV" in KODI
# Including the file extensions is for people that don't change default
# stream names.
videostream_keywords = ["Video", "TV", "Testbild", "mpeg", "mpg", "m2t", "m2ts", "ts"]

# -t/--tvgurl option default.
# Add 'url-tvg' and 'x-tvg-url' tags to M3U files?
# Only makes sense if files are available under '/xmltv' on your AzuraCast server,
# i.e. like 'https://example.com/xmltv/example.com.xml'.
add_tvg_url = False

# -i/--icon option default:
# You can provide a channel icon, for example from the station's web page.
# If omitted, we will use the station's Default Album Art (set in "Branding").
channel_icon_url = None

# -c/--customplayer option default:
# You can provide another than the standard web player URL,
# for example a customized web player on the station's web page.
# If omitted, we will use the station's default web player URL.
custom_player_url = None

# -o/--output option default:
# If you don't want files to be written into the current folder,
# specify an output folder here. (Empty string, NOT None.)
output_folder = ""

# -d/--days option default:
# EPG for how many days?
num_days = 7

# -f/--fillgaps option default:
# Fill gaps in a station's programmes (True/False)?
fill_gaps = False

# -g/--gzip option default
# This will create an additional gzip-compressed (.gz) version of the XML EPG file.
# Many clients support thus format, and it speeds up transmission to the
# clients.
add_gzip = True

# --rss option default:
# Create/update RSS Feeds (one per station plus an aggregated one for ALL stations)
# Only makes sense if files are available under '/xmltv' on your AzuraCast server,
# i.e. like 'https://example.com/xmltv/example.com.rss'.
make_rss = False

# *** END OF USER CONFIGURABLE DEFAULTS -- DO NOT MODIFY ANYTHING BELOW ***

# XMLTV server path -- DO NOT CHANGE!
xmltv_path = "/xmltv"


import os
import sys

ME = os.path.basename(sys.argv[0])  # should we better use __file__?


def errprint(*args, **kwargs):
    """Print error messages to stderr, nicely."""
    print(ME + ":", "error:", *args, file=sys.stderr, **kwargs)


# try importing everything upfront (no lazy late imports)
# because we want to know which modules might be missing on first install
try:
    import argparse
    import datetime as dt
    import gzip
    import json
    import re
    import shutil
    import textwrap
    from email import utils  # for RSS Feed dates
    from urllib.parse import urlparse

    import lxml.etree as et
    import requests
except Exception as error:
    errprint(type(error).__name__, "–", error)
    sys.exit(1)


def urljoin(*args):
    """Safely join parts of an URL.

    TODO: Fix second slash being removed from scheme like "https://".
    """
    # remove "None" args, convert others to str and strip
    args = [str(x).strip() for x in args if x is not None]
    # save trailing slash
    trailing_slash = "/" if args[-1].endswith("/") else ""
    # remove extra "/" and join to path
    return "/".join(filter(None, [x.strip("/") for x in args])) + trailing_slash


class AzuraCastAPI:
    """AzuraCast API interface, strictly JSON."""

    def __init__(self, instance_url, api_key="", timeout=30):
        self.instance_url = instance_url
        self.api_key = api_key
        self.timeout = timeout  # default None = until connection closed
        self.status_code = 0
        self.content_type = ""  # response content-type
        self.headers = {
            "User-Agent": f"{APPNAME}/{VERSION} +{APPURL}",
            "accept": "application/json",
            "X-Clacks-Overhead": "GNU Terry Pratchett, Leonard Nimoy",
        }
        if api_key:
            self.headers["X-API-Key"] = api_key

    def verify(self):
        """Verify this is actually an AzuraCast server
        by checking the /status API endpoint and online state."""

        # Make a HEAD request first, avoiding download of large files
        # or streams. User input can be erroneous, or even malicious.
        try:
            response = requests.head(
                urljoin(self.instance_url, "/api", "/status"),
                headers=self.headers,
                timeout=self.timeout,
            )
        except Exception as error:
            errprint(type(error).__name__, "–", error)
            sys.exit(1)

        # fail if status != 200 or not JSON
        if (
            response.status_code != requests.codes.ok
            or "application/json" not in response.headers.get("Content-Type", "")
        ):
            return False

        # ok so far, do a GET and check if "online" is there and "true"
        response = self.get("/status")
        return response and response.get("online", False)

    def get(self, endpoint, params={}, quit_on_error=False):
        """Get API JSON resonse; return empty list on error (or quit)."""
        try:
            response = requests.get(
                urljoin(self.instance_url, "/api", endpoint),
                headers=self.headers,
                params=params,
                timeout=self.timeout,
            )
            self.status_code = response.status_code
            self.content_type = response.headers.get("Content-Type", "")
            response.raise_for_status()
        except Exception as error:
            errprint(type(error).__name__, "–", error)
            if quit_on_error:
                sys.exit(1)
            else:
                # empty list = "nothing" for further processing by caller
                return []

        # response must be JSON (else JSON decoder will throw error)
        if "application/json" in self.content_type:
            return response.json()
        else:
            return []

    def fail(self):
        return (
            self.status_code != requests.codes.ok
            or "application/json" not in self.content_type
        )


def sanitize(name):
    """Sanitize a station shortname to become RFC2838-compliant."""
    # strip, replace ' ' & '_' with '-' (no '_' allowed in domains)
    name = name.strip().translate(str.maketrans(" _", "--"))
    keep = "-."
    # remove everything that isn't alphanumeric (Unicode-aware) or to be kept
    return "".join(c for c in name if c.isalnum() or c in keep)


def clean_text(description):
    """Remove all leftover whitespace from a programme description, not using re."""
    text = description.strip()
    lines = [line.split() for line in text.splitlines()]
    return "\n".join(" ".join(word for word in line) for line in lines)


def replace_vars(dictionary, text):
    """Replace moustache-type variables in text (one level deep)."""
    # The dictionary is a simple key, value dict like so:
    # {
    #   "{variable1}": "replacement text 1",
    #   "{variable2}": "replacement 2"
    # }
    for variable in dictionary:
        if dictionary[variable]:
            text = text.replace(variable, dictionary[variable])
        else:
            # replace with an empty string if Falsy (i.e. JSON null from API)
            text = text.replace(variable, "")
    return text


def is_video(name, keywords):
    """Try to determine if a stream is a video stream
    by checking a list of keywords."""

    # casefold keywords for comparison, just in case
    keywords = [k.casefold() for k in keywords]

    is_video = False

    # see if any of the words in the stream name match a "video stream" keyword
    words = re.findall("(\\w+)", name.casefold())
    for word in words:
        if word in keywords:
            is_video = True
    return is_video


def get_stations(api, channel_icon_url="", public_only=True, videostream_keywords=[]):
    """Get station info from this instance."""
    stations = []

    r = api.get("/stations")

    for station in r:
        # get station's default album art; we use this as station logo
        # we use a little trick here by requesting the artwork for non-existing medium "0",
        # which will cause AzuraCast to look up station branding and
        # instance branding for a replacement. It returns the actual image, not
        # a URL.
        if channel_icon_url:
            channel_icon = channel_icon_url
        else:
            channel_icon = urljoin(
                api.instance_url, "/api/station/", station["id"], "/art/0"
            )
        s = {
            "id": station["id"],
            "channel_id": sanitize(station["shortcode"])
            + "."
            + urlparse(instance_url).hostname,
            "icon": channel_icon,  # not yet from API
            "name": station["name"],
            "shortcode": station["shortcode"],
            "description": station["description"],
            "is_public": station["is_public"],
            "url": station["url"],
            "public_player_url": custom_player_url
            if custom_player_url
            else station["public_player_url"],
            "mounts": [],
            "playlists": [],
            "streamers": [],
        }

        # if an API key is given, we can provide a much richer output, notably:
        #   - include mounts not visible on public pages (like a video stream)
        #   - show if listener requests are allowed in programmes (from playlists)
        #   - show presenter info (like a streamer image) in programmes (from streamers)
        if api.api_key:
            # get mount info, to include otherwise invisible mounts
            # (silent) HTTPErr 500 if this station has no mounts
            # (Broadcasting off, HLS-only, etc.) -- api.get will return []
            rm = api.get(urljoin("/station/", station["id"], "/mounts"))

            for mount in rm:
                m = {
                    "id": mount["id"],
                    "name": mount["display_name"],
                    "is_public": mount["is_public"],
                    "is_default": mount["is_default"],
                    "is_video": is_video(mount["display_name"], videostream_keywords),
                    "url": mount["links"]["listen"],
                }
                if public_only:
                    if mount["is_public"]:
                        s["mounts"].append(m)
                else:
                    s["mounts"].append(m)

            # get playlist info, to later show if listener requests are allowed
            # in the programme items
            rp = api.get(urljoin("/station/", station["id"], "/playlists"))

            for playlist in rp:
                p = {
                    "id": playlist["id"],
                    "name": playlist["name"],
                    "type": playlist["type"],
                    "source": playlist["source"],
                    "remote_url": playlist["remote_url"],
                    "is_jingle": playlist["is_jingle"],
                    "include_in_on_demand": playlist["include_in_on_demand"],
                    "include_in_requests": playlist["include_in_requests"],
                    "is_scheduled": playlist["schedule_items"] != [],
                }
                # store list of schedules (IDs) this playlist is in,
                # so we can find the correct one in get_programme()
                # if multiple playlists have the same name (which IS allowed)
                p["schedule_ids"] = [d.get("id") for d in playlist["schedule_items"]]

                if playlist["is_enabled"]:
                    s["playlists"].append(p)

            # get streamer info, to include image in programme's presenter info
            rs = api.get(urljoin("/station/", station["id"], "/streamers"))

            for streamer in rs:
                dj = {
                    "id": streamer["id"],
                    "streamer_username": streamer["streamer_username"],
                    "name": streamer["display_name"],
                    "art": streamer["art"],
                    # Be careful: UI says "INTERNAL commments ony",
                    # but _could_ be used for a description
                    "comments": streamer["comments"],
                }
                s["streamers"].append(dj)

        else:
            # no API key, just use the visible standard mounts
            for mount in station["mounts"]:
                m = {
                    "id": mount["id"],
                    "name": mount["name"],
                    "is_default": mount["is_default"],
                    "is_video": is_video(mount["name"], videostream_keywords),
                    "url": mount["url"],
                }
                s["mounts"].append(m)

        if station["hls_enabled"]:
            # HLS has no "is_default" (yet), we simply set it to False
            m = {
                "name": station["name"] + " (HLS)",
                "url": station["hls_url"],
                "is_default": False,
                "is_video": False,
            }
            # future: if API returns "hls_is_default" (False if not)
            m["is_default"] = station.get("hls_is_default", False)
            s["mounts"].append(m)

        # sort mounts by display name, put default mount(s) at beginning
        # this is intended for players that immediately start playout,
        # and for better human readability
        s["mounts"] = sorted(
            s["mounts"], key=lambda k: (not k["is_default"], k["name"])
        )

        if public_only:
            if station["is_public"]:
                stations.append(s)
        else:
            stations.append(s)

    return stations


def create_m3u(
    instance_url,
    station,
    groups,
    output_folder="",
    add_tvg_url=False,
    add_radio_tag=False,
):
    """Create an M3U playlist for a single station."""

    # create outfile from folder + station shortname + '.m3u'
    outfile = os.path.join(output_folder, sanitize(station["shortcode"]) + ".m3u")
    print(f"Writing XMLTV Tuner file (M3U playlist): {outfile}")

    with open(outfile, "w") as f:
        if add_tvg_url:
            # -t/-tvgurl option: add links to the EPG on the '#EXTM3U' line;
            # MUST be reachable under /xmltv
            tvg_url = urljoin(
                instance_url, xmltv_path, urlparse(instance_url).hostname + ".xml"
            )
            f.write(f'#EXTM3U url-tvg="{tvg_url}" x-tvg-url="{tvg_url}"\n')
        else:
            # no links
            f.write("#EXTM3U\n")

        # build "group-title": supports ";"-delimited multiple groups
        # empty group replaced by station name
        groups = ";".join([g.strip() or station["name"] for g in groups.split(";")])

        for mount in station["mounts"]:
            radio_tag = (
                'radio="true" ' if add_radio_tag and not mount["is_video"] else ""
            )
            f.write(
                f'#EXTINF:-1 tvg-name="{mount["name"]}" group-title="{groups}" {radio_tag}tvg-id="{station["channel_id"]}" tvg-logo="{station["icon"]}",{mount["name"]}\n'
            )
            f.write(mount["url"] + "\n")


def create_m3u_all(
    instance_url,
    stations,
    groups,
    output_folder="",
    add_tvg_url=False,
    add_radio_tag=False,
):
    """Create an M3U playlist for all stations."""

    # create outfile from folder + domain.name + '.m3u'
    outfile = os.path.join(output_folder, urlparse(instance_url).hostname + ".m3u")
    print(f"Writing XMLTV Tuner file (M3U playlist): {outfile}")

    with open(outfile, "w") as f:
        if add_tvg_url:
            # -t/-tvgurl option: add links to the EPG on the '#EXTM3U' line; MUST be reachable under /xmltv
            tvg_url = urljoin(
                instance_url, xmltv_path, urlparse(instance_url).hostname + ".xml"
            )
            f.write(f'#EXTM3U url-tvg="{tvg_url}" x-tvg-url="{tvg_url}"\n')
        else:
            # no links
            f.write("#EXTM3U\n")

        for station in stations:
            # build "group-title": supports ";"-delimited multiple groups
            # empty group replaced by station name
            group_title = ";".join(
                [g.strip() or station["name"] for g in groups.split(";")]
            )

            for mount in station["mounts"]:
                radio_tag = (
                    'radio="true" ' if add_radio_tag and not mount["is_video"] else ""
                )
                # better readable for humans: #EXTINF:-1 Name Group Radio? ID
                # Logo,Name
                f.write(
                    f'#EXTINF:-1 tvg-name="{mount["name"]}" group-title="{group_title}" {radio_tag}tvg-id="{station["channel_id"]}" tvg-logo="{station["icon"]}",{mount["name"]}\n'
                )
                f.write(mount["url"] + "\n")


def create_gap_fillers(station, programmes):
    """Find gaps between programmes, return list of "gap filler" entries."""

    if len(programmes) <= 1:
        return []

    # find playlists that constitute the general rotation
    # (enabled, type default, not on schedule)
    pl = [
        item
        for item in station["playlists"]
        if item["type"] == "default" and not item["is_scheduled"]
    ]

    # make a comma-separated string where the last element is separated by '&' instead
    # ex: '', 'a', 'a & b', 'a, b & c', ...
    names = [item["name"] for item in pl]
    playlists = " & ".join(filter(None, [", ".join(names[:-1])] + names[-1:]))

    # see if any of them have requests enabled
    requests_enabled = any([item for item in pl if item["include_in_requests"]])

    # sort by start times
    programmes = sorted(programmes, key=lambda x: x["start"])

    # set up text replacers
    replacers = {
        "{playlists}": playlists,
        "{request_url}": station["public_player_url"],
        "{station_name}": station["name"],
        "{station_description}": station["description"],
        "{station_website}": station["url"],
        "{player_url}": station["public_player_url"],
        "{category}": category,  # global
    }

    gaps = []

    # start at the end of the first range
    now = programmes[0]["stop"]

    # iterate through programmes, ignoring the first range
    for pair in programmes[1:]:
        # if next start time is before current stop time, keep going until we find a gap
        # if next start time is after current end time, found the first gap
        if pair["start"] > now:
            # create a new gap filler programme
            # use programme's start year for '{year}'
            replacers["{year}"] = pair["start"][0:4]
            p = {
                "channel": station["channel_id"],
                "start": now,
                "stop": pair["start"],
                "title": replace_vars(replacers, gap_filler_title),
                "sub-title": replace_vars(replacers, gap_filler_subtitle),
                "desc": replace_vars(replacers, gap_filler_description),
                "category": category,
                "credits": [],
            }
            # parse again if listener requests enabled
            if requests_enabled:
                replacers["{playlist}"] = p["title"]
                p["title"] = replace_vars(replacers, requests_enabled_title)
                p["sub-title"] = replace_vars(replacers, requests_enabled_subtitle)
                p["desc"] = p["desc"] + replace_vars(
                    replacers, requests_enabled_description
                )

            # add extra info to description
            p["desc"] = p["desc"].rstrip() + replace_vars(
                replacers, append_to_description
            )

            # remove leftover whitespace from description
            p["desc"] = clean_text(p["desc"])

            gaps.append(p)

        # need to advance 'now' only if the next end time is past the current
        # end time
        now = max(pair["stop"], now)

    return gaps


def rfc3339_date(dt, utc_z=False):
    """Return datetime object as RFC 3339 string, an ISO 8601 profile.
    Compatible with W3C-DTF format.
    utc_z=True outputs "Z" instead of "+00:00" for UTC datetimes."""

    if dt.tzinfo is None:
        suffix = "-00:00"  # unknown offset, naive dt
    else:
        # use "%z" because "%:z" not yet supported everywhere
        suffix = dt.strftime("%z")
        suffix = suffix[:-2] + ":" + suffix[-2:]
        if utc_z and suffix == "+00:00":
            suffix = "Z"
    return dt.strftime("%Y-%m-%dT%H:%M:%S") + suffix


def get_programme(api, station, num_days=num_days, fill_gaps=False):
    """Get a channel's programme."""

    programmes = []

    # changed the old, sub-optimal API call using 'now' against this:
    # it uses the (undocumented) 'start' end 'end' parameters
    # of the /station/{station_id}/schedule API endpoint

    # start today at midnight
    start = dt.datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    # end requested number of days later
    end = start + dt.timedelta(days=num_days)

    # API expects RFC 3339 datetime string
    start = rfc3339_date(start.astimezone())
    end = rfc3339_date(end.astimezone())

    params = {"start": start, "end": end}
    r = api.get(urljoin("/station/", station["id"], "/schedule"), params=params)

    for r_pgm in r:
        p = {
            "id": r_pgm["id"],
            "type": r_pgm["type"],
            "channel": station["channel_id"],
            "start": dt.datetime.strptime(r_pgm["start"], "%Y-%m-%dT%H:%M:%S%z")
            .astimezone()
            .strftime("%Y%m%d%H%M%S %z"),
            "stop": dt.datetime.strptime(r_pgm["end"], "%Y-%m-%dT%H:%M:%S%z")
            .astimezone()
            .strftime("%Y%m%d%H%M%S %z"),
            "title": r_pgm["title"],
            "sub-title": "",
            "desc": r_pgm["description"],
            "category": category,
            "credits": [],
        }

        # try to enrich programme with playlist info
        if r_pgm["type"] == "playlist":
            # Find the CORRECT playlist if more than one playlist has the same name
            # Playlist Name and Schedule ID must match.
            pl = next(
                (
                    item
                    for item in station["playlists"]
                    if item["name"] == r_pgm["name"]
                    and r_pgm["id"] in item["schedule_ids"]
                ),
                None,
            )

            # playlist has listener requests enabled, enrich title, sub-title,
            # and description
            if pl and pl["include_in_requests"]:
                replacers = {
                    "{playlist}": pl["name"],
                    "{request_url}": station["public_player_url"],
                    "{station_name}": station["name"],
                    "{station_description}": station["description"],
                    "{station_website}": station["url"],
                    "{player_url}": station["public_player_url"],
                    "{year}": r_pgm["start"][0:4],
                    "{category}": category,  # global
                }
                p["title"] = replace_vars(replacers, requests_enabled_title)
                p["sub-title"] = replace_vars(replacers, requests_enabled_subtitle)
                p["desc"] = r_pgm["description"].rstrip() + replace_vars(
                    replacers, requests_enabled_description
                )

            # playlist is syndicated content (remote)
            if pl and pl["source"] == "remote_url":
                replacers = {
                    "{playlist}": pl["name"],
                    "{remote_url}": pl["remote_url"],
                    "{station_name}": station["name"],
                    "{station_description}": station["description"],
                    "{station_website}": station["url"],
                    "{player_url}": station["public_player_url"],
                    "{year}": r_pgm["start"][0:4],
                    "{category}": category,  # global
                }
                p["title"] = replace_vars(replacers, remote_title)
                p["sub-title"] = replace_vars(replacers, remote_subtitle)
                p["desc"] = r_pgm["description"].rstrip() + replace_vars(
                    replacers, remote_description
                )

        # try to enrich programme with streamer info
        if r_pgm["type"] == "streamer":
            # try to find the corresponding streamer by name (sadly, no ID)
            dj = next(
                (
                    item
                    for item in station["streamers"]
                    if item["name"] == r_pgm["name"]
                ),
                None,
            )

            if dj:
                # found the streamer, use their info (and image)
                replacers = {
                    "{presenter}": dj["name"],
                    "{image_url}": dj["art"],
                    "{comments}": dj["comments"],
                    "{station_name}": station["name"],
                    "{station_description}": station["description"],
                    "{station_website}": station["url"],
                    "{player_url}": station["public_player_url"],
                    "{year}": r_pgm["start"][0:4],
                    "{category}": category,  # global
                }

                p["title"] = replace_vars(replacers, live_title)
                p["sub-title"] = replace_vars(replacers, live_subtitle)
                p["desc"] = r_pgm["description"].rstrip() + replace_vars(
                    replacers, live_description
                )
                p["credits"].append(
                    {"presenter": {"name": dj["name"], "image": dj["art"]}}
                )
            else:
                # streamer not provided, make for some general niceness
                replacers = {
                    "{presenter}": r_pgm["name"],
                    "{image_url}": "",
                    "{comments}": "",
                    "{station_name}": station["name"],
                    "{station_description}": station["description"],
                    "{station_website}": station["url"],
                    "{player_url}": station["public_player_url"],
                    "{year}": r_pgm["start"][0:4],
                    "{category}": category,  # global
                }
                p["title"] = replace_vars(replacers, live_title)
                p["sub-title"] = replace_vars(replacers, live_subtitle)
                p["desc"] = r_pgm["description"].rstrip() + replace_vars(
                    replacers, live_description
                )
                p["credits"].append({"presenter": {"name": r_pgm["name"]}})

        # add extra info to description
        replacers = {
            "{station_name}": station["name"],
            "{station_description}": station["description"],
            "{station_website}": station["url"],
            "{player_url}": station["public_player_url"],
            "{year}": r_pgm["start"][0:4],
            "{category}": category,  # global
        }
        p["desc"] = p["desc"].rstrip() + replace_vars(replacers, append_to_description)

        # remove extra whitespace from description
        p["desc"] = clean_text(p["desc"])

        programmes.append(p)

    # and here starts the tedious work of removing the duplicates...
    # de-duplicate using a set (returns an unsorted list!)
    set_of_jsons = {json.dumps(d, sort_keys=True) for d in programmes}
    programmes = [json.loads(t) for t in set_of_jsons]

    # fill any gaps between programmes, if so requested
    if fill_gaps:
        programmes = programmes + create_gap_fillers(station, programmes)

    # sort by start time
    programmes = sorted(programmes, key=lambda k: k["start"])

    return programmes


def create_xmltv(instance_url, stations, programmes, output_folder="", add_gzip=False):
    """Create an XMLTV EPG for all stations."""

    # create outfile from folder + domain.name + '.xml'
    outfile = os.path.join(output_folder, urlparse(instance_url).hostname + ".xml")
    print(f"Writing XMLTV EPG file: {outfile}")

    # set up the root
    date = dt.datetime.now().astimezone().strftime("%Y%m%d%H%M%S %z")

    root = et.Element(
        "tv",
        attrib={
            "date": date,
            "source-info-url": instance_url,
            "source-info-name": urlparse(instance_url).netloc,
            "generator-info-name": APPNAME + " " + VERSION,
            "generator-info-url": APPURL,
        },
    )

    # set up the channels
    for station in stations:
        channel = et.SubElement(root, "channel", attrib={"id": station["channel_id"]})
        et.SubElement(channel, "display-name").text = station["name"]
        if station["icon"]:
            et.SubElement(channel, "icon", attrib={"src": station["icon"]})

    # set up programs
    for s_pgm in programmes:
        for r_pgm in s_pgm:
            attrib_lang = {"lang": language}
            programme_attrib = dict(
                start=r_pgm["start"], stop=r_pgm["stop"], channel=r_pgm["channel"]
            )
            programme = et.SubElement(root, "programme", attrib=programme_attrib)
            et.SubElement(programme, "title", attrib=attrib_lang).text = r_pgm["title"]
            # leave out empty subtitles since some programs throw warnings
            if r_pgm["sub-title"]:
                et.SubElement(programme, "sub-title", attrib=attrib_lang).text = r_pgm[
                    "sub-title"
                ]
            et.SubElement(programme, "desc", attrib=attrib_lang).text = r_pgm["desc"]

            credits = et.SubElement(programme, "credits")

            # see if we have a presenter in credits
            presenter = next(
                (
                    item["presenter"]
                    for item in r_pgm["credits"]
                    if item.get("presenter")
                ),
                None,
            )
            if presenter:
                # add presenter credit and image (if available)
                credit = et.SubElement(credits, "presenter")
                credit.text = presenter["name"]
                if presenter.get("image"):
                    et.SubElement(
                        credit, "image", attrib={"type": "person"}
                    ).text = presenter["image"]

            et.SubElement(programme, "category", attrib=attrib_lang).text = r_pgm[
                "category"
            ]

    with et.xmlfile(outfile, encoding="UTF-8") as xf:
        xf.write_declaration()
        xf.write_doctype('<!DOCTYPE tv SYSTEM "xmltv.dtd">')
        xf.write(root, pretty_print=True)

    # create gzip-compressed (.gz) file if requested
    if add_gzip:
        infile = os.path.join(output_folder, urlparse(instance_url).hostname + ".xml")
        outfile = infile + ".gz"
        print(f"Writing XMLTV EPG gzip file: {outfile}")

        with open(infile, "rb") as f_in:
            with gzip.open(outfile, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)


def linkify_urls(text):
    """
    (Try to) replace any URLs in text with anchor links, for HTML conversion.

    Based on John Gruber’s article: https://daringfireball.net/2010/07/improved_regex_for_matching_urls
    and Gist: https://gist.github.com/gruber/249502
    "Liberal Regex Pattern for Any URLs"
    """
    urls = re.compile(
        r"(?i)\b((?:[a-z][\w-]+:(?:/{1,3}|[a-z0-9%])|www\d{0,3}[.]|[a-z0-9.\-]+[.][a-z]{2,4}/)(?:[^\s()<>]+|\(([^\s()<>]+|(\([^\s()<>]+\)))*\))+(?:\(([^\s()<>]+|(\([^\s()<>]+\)))*\)|[^\s`!()\[\]{};:'\".,<>?«»“”‘’]))",
        re.MULTILINE | re.UNICODE,
    )
    text = urls.sub(r'<a href="\1" target="_blank">\1</a>', text)
    return text


def create_rss_station(instance_url, station, programmes, output_folder=""):
    """Create an RSS Feed for a single station."""

    # create outfile from folder + station shortname + '.rss'
    outfile = os.path.join(output_folder, sanitize(station["shortcode"]) + ".rss")
    print(f"Writing RSS Feed file: {outfile}")

    # set up the root
    created_on = utils.formatdate(localtime=True)  # RFC2822 format
    year = dt.datetime.now().strftime("%Y")  # copyright year
    copyright_text = f"Copyright © {year} {station['name']}"

    # et.register_namespace("atom", "http://www.w3.org/2005/Atom")
    nsmap = {
        "atom": "http://www.w3.org/2005/Atom",
        "media": "http://search.yahoo.com/mrss/",
        "fh": "http://purl.org/syndication/history/1.0",
        "dcterms": "http://purl.org/dc/terms/",
    }
    root = et.Element("rss", attrib={"version": "2.0"}, nsmap=nsmap)

    # set up the channel
    channel = et.SubElement(root, "channel")

    self_url = urljoin(
        instance_url, xmltv_path, sanitize(station["shortcode"]) + ".rss"
    )
    et.SubElement(
        channel,
        "{http://www.w3.org/2005/Atom}link",
        attrib={"href": self_url, "rel": "self", "type": "application/rss+xml"},
    )

    et.SubElement(channel, "title").text = station["name"]
    et.SubElement(channel, "link").text = station["url"]
    et.SubElement(channel, "description").text = station["description"]

    et.SubElement(channel, "language").text = language
    et.SubElement(channel, "pubDate").text = created_on
    et.SubElement(channel, "lastBuildDate").text = created_on
    et.SubElement(channel, "generator").text = f"{APPNAME} {VERSION}"
    et.SubElement(channel, "copyright").text = copyright_text

    if station["icon"]:
        image = et.SubElement(channel, "image")
        et.SubElement(image, "url").text = station["icon"]
        et.SubElement(image, "title").text = station["name"]
        et.SubElement(image, "link").text = station["url"]
    if category:
        et.SubElement(channel, "category").text = category

    # set <fh:complete/> to indicate this feed is "the complete set"
    # and the feed reader should ignore other, previously downloaded historic
    # data
    et.SubElement(channel, "{http://purl.org/syndication/history/1.0}complete")

    # fetch programmes of this station (by channel_id)
    s_pgm = []
    for s in programmes:
        s_pgm = s_pgm + [pgm for pgm in s if pgm["channel"] == station["channel_id"]]

    # sort by start time
    s_pgm = sorted(s_pgm, key=lambda k: k["start"])

    # create the channel items
    for r_pgm in s_pgm:
        item = et.SubElement(channel, "item")
        et.SubElement(item, "title").text = r_pgm["title"]
        et.SubElement(item, "link").text = station["public_player_url"]

        # prepare some vars
        start_dt = dt.datetime.strptime(r_pgm["start"], "%Y%m%d%H%M%S %z").astimezone()
        stop_dt = dt.datetime.strptime(r_pgm["stop"], "%Y%m%d%H%M%S %z").astimezone()
        year = start_dt.strftime("%Y")

        airdate = dt.datetime.strftime(start_dt, "%F")
        airtime = (
            dt.datetime.strftime(start_dt, "%H:%M")
            + "–"
            + dt.datetime.strftime(stop_dt, "%H:%M")
        )

        # Airtime length in hours and minutes
        airtime_length_td = stop_dt - start_dt
        airtime_length_mins = airtime_length_td.seconds // 60
        airtime_length = (
            "{0:2}".format(airtime_length_mins // 60)
            + ":"
            + "{0:02}".format(airtime_length_mins % 60)
        )  # + ':00'
        airtime_length = airtime_length.strip()

        # EPG <desc> allows newlines, make them <br/> for prettier display
        desc = "<br/>".join(r_pgm["desc"].splitlines())

        # replacers
        replacers = {
            "{station_name}": station["name"],
            "{station_description}": station["description"],
            "{station_website}": station["url"],
            "{player_url}": station["public_player_url"],
            "{year}": r_pgm["start"][0:4],
            "{category}": category,  # global
            "{title}": r_pgm["title"],
            "{subtitle}": r_pgm["sub-title"],
            "{airdate}": airdate,
            "{airtime}": airtime,
            "{airtime_length}": airtime_length,
            "{desc}": desc,
        }

        description = replace_vars(replacers, rss_feed_description)

        # remove extra whitespace from description
        description = clean_text(description)

        # make URLs clickable in HTML
        description = linkify_urls(description)

        et.SubElement(item, "description").text = description
        et.SubElement(item, "category").text = r_pgm["category"]

        pub_date = utils.formatdate(start_dt.timestamp(), localtime=True)
        et.SubElement(item, "pubDate").text = pub_date

        # construct guid of channel_id and programme start time
        guid = r_pgm["channel"] + "-" + start_dt.strftime("%Y%m%d%H%M%S")
        et.SubElement(item, "guid", attrib={"isPermaLink": "false"}).text = guid

        # use <dcterms:valid> to put validity on the ITEM (not every media element)
        # start and end use W3C-DTF datetime format
        start = rfc3339_date(start_dt, utc_z=True)
        end = rfc3339_date(stop_dt, utc_z=True)
        et.SubElement(
            item, "{http://purl.org/dc/terms/}valid"
        ).text = f"start={start}; end={end}; scheme=W3C-DTF"

        # media:... elements: Put all streams and the player link in a media
        # group
        media_group = et.SubElement(item, "{http://search.yahoo.com/mrss/}group")
        # iterate over credits, trying to find a presenter image
        # else use station icon instead
        thumbnail = next(
            (
                item["presenter"]["image"]
                for item in r_pgm["credits"]
                if item.get("presenter", {}).get("image")
            ),
            station["icon"],
        )
        if thumbnail:
            et.SubElement(
                media_group,
                "{http://search.yahoo.com/mrss/}thumbnail",
                attrib={"url": thumbnail},
            )

        et.SubElement(
            media_group,
            "{http://search.yahoo.com/mrss/}player",
            attrib={
                "url": station["public_player_url"],
                "width": "800",
                "height": "450",
            },
        )

        for mount in station["mounts"]:
            url = mount["url"]
            medium = "video" if mount["is_video"] else "audio"
            is_default = mount["is_default"]
            expression = "nonstop"  # stream
            title = mount["name"]  # type="plain", stream name

            media_content = et.SubElement(
                media_group,
                "{http://search.yahoo.com/mrss/}content",
                attrib={
                    "url": url,
                    "medium": medium,
                    "isDefault": "true" if is_default else "false",
                    "expression": expression,
                    "lang": language,
                },
            )
            # sadly, not many readers use this yet; it should provide the mount
            # name as title of the media:content
            et.SubElement(
                media_content,
                "{http://search.yahoo.com/mrss/}title",
                attrib={"type": "plain"},
            ).text = title

    with et.xmlfile(outfile, encoding="UTF-8") as xf:
        xf.write_declaration()
        xf.write(root, pretty_print=True)


# some tests for arparse


def valid_url(arg):
    """Check if argument is a valid URL (scheme + domain)."""
    url = urlparse(arg)
    if all((url.scheme, url.netloc)):
        return arg
    raise argparse.ArgumentTypeError(f"Invalid URL: '{arg}'")


def valid_url_path(arg):
    """Check if argument is a valid URL (scheme + domain + path)."""
    url = urlparse(arg)
    if arg == "" or all((url.scheme, url.netloc, url.path)):
        return arg
    raise argparse.ArgumentTypeError(f"Invalid URL (path missing): '{arg}'")


def valid_path(arg):
    """Check if argument is a valid output folder path."""
    arg = os.path.normpath(arg)
    if os.path.isdir(arg):
        return arg
    raise argparse.ArgumentTypeError(f"Not a folder: '{arg}'")


class Range(argparse.Action):
    def __init__(self, minimum=None, maximum=None, *args, **kwargs):
        self.min = minimum
        self.max = maximum
        # kwargs["metavar"] = "[%d-%d]" % (self.min, self.max)
        super().__init__(*args, **kwargs)

    def __call__(self, parser, namespace, value, option_string=None):
        if not (self.min <= value <= self.max):
            msg = "invalid choice: %r (choose from [%d-%d])" % (
                value,
                self.min,
                self.max,
            )
            raise argparse.ArgumentError(self, msg)
        setattr(namespace, self.dest, value)


class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter):
    """Format output like ArgumentDefaultsHelpFormatter & RawDescriptionHelpFormatter but wrap nicely."""

    def _fill_text(self, text, width, indent):
        lines = text.strip().splitlines(keepends=True)
        new = []
        # if 'replace_whitespace=False' is used, textwrap makes a mess
        # we need to call it line by line
        for line in lines:
            new.append(
                "\n".join(
                    textwrap.wrap(
                        line,
                        width,
                        initial_indent=indent,
                        subsequent_indent=indent,
                        replace_whitespace=False,
                    )
                )
            )
        return "\n".join(new)


parser = argparse.ArgumentParser(
    description="Create XMLTV Tuner, EPG and RSS Feed files from an AzuraCast Web Radio.",
    epilog=f"""
%(prog)s can create XMLTV M3U Tuner, XML EPG and RSS 2.0 Feed files for both your own and other AzuraCast stations.

For much better programme data to be generated, create an AzuraCast API key and use the -a/--apikey option, which allows:
  - using otherwise invisible mounts, like an added video stream,
  - showing listener request info if a playlist has requests enabled
  - adding a presenter image on live shows, and (mis-)using the streamer comment field as a description
  - showing extra info for syndicated content (remote playlists)

--group GROUP modifies the 'group-title' in M3U Tuner files. It normally contains the station name. Using this, you can group all stations of an AzuraCast server under a common name, or use something like 'Radio-DE' to merge with larger, existing lists. A very few clients, like KODI, support multiple groups. Separate these with a semicolon ';'. Empty values will be replaced by the station name: ';Radio-DE' --> 'Your Station;Radio-DE', 'Radio;;Radio-DE' --> 'Radio;Your Station;Radio-DE'.

-r/--radio adds a 'radio="true"' tag to the M3U #EXTINF lines, if a stream’s display name doesn’t contain any of the words {', '.join("'"+k+"'" for k in videostream_keywords)} (you can customize this list).
This is for software like KODI, which can distinguish between Radio and TV channels and displays these in separate menus.

-t/--tvgurl adds 'url-tvg' and 'x-tvg-url' tags to the M3U Tuner files. This helps media center software like KODI to automatically locate the corresponding EPG data file, but only works if the generated M3U and XML files are available under the '{xmltv_path}' path of your AzuraCast server.
See installation instructions at {APPURL}.

Output files are named after the (sanitized) station shortcode ("URL Stub" in AzuraCast), and the server base URL.

Edit '{argparse._sys.argv[0]}' using a text editor to change some defaults near the top of the file. No worries, everything is well documented.

Please report any issues to {APPURL}/issues.""",
    formatter_class=CustomFormatter,
)
parser.add_argument(
    "-v", "--version", action="version", version="%(prog)s " + __version__
)
parser.add_argument(
    "-u",
    "--url",
    type=valid_url,
    default=instance_url,
    help="base URL to an AzuraCast instance",
)
parser.add_argument(
    "-i",
    "--icon",
    metavar="URL",
    type=valid_url_path,
    default=channel_icon_url,
    help="URL to a channel icon; will use station's default album art if omitted",
)
parser.add_argument(
    "-c",
    "--customplayer",
    metavar="URL",
    type=valid_url_path,
    default=custom_player_url,
    help="URL to a custom web player; modifies {player_url} and {request_url} variables",
)
parser.add_argument(
    "-d",
    "--days",
    type=int,
    minimum=1,
    maximum=30,
    action=Range,
    default=num_days,
    help="number of days in the future [%(min)d-%(max)d] to include in the EPG",
)
parser.add_argument(
    "-f",
    "--fillgaps",
    action="store_true",
    default=fill_gaps,
    help="fill gaps between programmes with a 'General Rotation' entry",
)
parser.add_argument(
    "-o",
    "--output",
    metavar="FOLDER",
    type=valid_path,
    default=output_folder,
    help="output folder for XMLTV files",
)
parser.add_argument(
    "-a",
    "--apikey",
    default=api_key,
    help="AzuraCast API key; allows creating much better EPG data, see below",
)
parser.add_argument(
    "-p",
    "--public",
    action="store_true",
    default=public_only,
    help="include only public stations & streams",
)
parser.add_argument(
    "-m",
    "--m3u",
    action="store_true",
    default=make_m3u,
    help="create M3U XMLTV Tuner file(s); only needed on first run or after changes in AzuraCast",
)
parser.add_argument(
    "--group",
    type=str,
    default=m3u_group_title,
    help="set M3U 'group-title' to something other than station name (see below)",
)
parser.add_argument(
    "-r",
    "--radio",
    action="store_true",
    default=add_radio_tag,
    help="add 'radio=\"true\"' tags to M3U #EXTINF; allows distinction between radio and TV channels (see below)",
)
parser.add_argument(
    "-t",
    "--tvgurl",
    action="store_true",
    default=add_tvg_url,
    help="add 'tvg-url' tags to M3U file; allows software to find the corresponding EPG automatically (see below)",
)
parser.add_argument(
    "-g",
    "--gzip",
    action="store_true",
    default=add_gzip,
    help="additionally output a gzip-compressed (.gz) version of the EPG XML file; many clients can use this format, and it reduces transmission time and bandwidth",
)
parser.add_argument(
    "--rss",
    action="store_true",
    default=make_rss,
    help="create/update RSS 2.0 Feed(s); one feed per station",
)


def handle_instance(
    instance_url=instance_url,
    api_key=api_key,
    public_only=public_only,
    output_folder=output_folder,
    make_m3u=make_m3u,
    make_rss=make_rss,
    channel_icon_url=channel_icon_url,
    custom_player_url=custom_player_url,
    num_days=num_days,
    fill_gaps=fill_gaps,
    add_radio_tag=add_radio_tag,
    add_tvg_url=add_tvg_url,
    add_gzip=add_gzip,
    m3u_group_title=m3u_group_title,
):
    """Handle one AzuraCast instance."""

    # Init the AzuraCast API
    api = AzuraCastAPI(instance_url, api_key)
    # Check if actually talking to a live AzuraCast server
    if not api.verify():
        errprint(f"No live AzuraCast at: '{instance_url}'")
        sys.exit(1)

    # Get stations from this AzuraCast instance
    stations = get_stations(
        api,
        channel_icon_url=channel_icon_url,
        public_only=public_only,
        videostream_keywords=videostream_keywords,
    )

    # Create M3U playlist files
    if make_m3u:
        for station in stations:
            create_m3u(
                instance_url,
                station,
                m3u_group_title,
                output_folder=output_folder,
                add_tvg_url=add_tvg_url,
                add_radio_tag=add_radio_tag,
            )
        create_m3u_all(
            instance_url,
            stations,
            m3u_group_title,
            output_folder=output_folder,
            add_tvg_url=add_tvg_url,
            add_radio_tag=add_radio_tag,
        )

    # Get schedules from all stations
    programmes = []
    for station in stations:
        programmes.append(get_programme(api, station, num_days, fill_gaps))

    # Create XMLTV file, add gzipped .gz version if requested
    create_xmltv(
        instance_url,
        stations,
        programmes,
        output_folder=output_folder,
        add_gzip=add_gzip,
    )

    # Create RSS Feed files
    if make_rss:
        for station in stations:
            create_rss_station(
                instance_url, station, programmes, output_folder=output_folder
            )


def main():
    """Main (runs if executed directly)."""

    args = parser.parse_args()

    instance_url = args.url
    api_key = args.apikey
    public_only = args.public
    output_folder = args.output + "/"
    make_m3u = args.m3u
    make_rss = args.rss
    channel_icon_url = args.icon
    custom_player_url = args.customplayer
    num_days = args.days
    fill_gaps = args.fillgaps
    add_radio_tag = args.radio
    add_tvg_url = args.tvgurl
    add_gzip = args.gzip
    m3u_group_title = args.group

    handle_instance(
        instance_url=instance_url,
        api_key=api_key,
        public_only=public_only,
        output_folder=output_folder,
        make_m3u=make_m3u,
        make_rss=make_rss,
        channel_icon_url=channel_icon_url,
        custom_player_url=custom_player_url,
        num_days=num_days,
        fill_gaps=fill_gaps,
        add_radio_tag=add_radio_tag,
        add_tvg_url=add_tvg_url,
        add_gzip=add_gzip,
        m3u_group_title=m3u_group_title,
    )


if __name__ == "__main__":
    main()
